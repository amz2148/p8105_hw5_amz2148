---
title: "p8105_hw5_amz2148"
output: github_document
---

Data Science: Homework 5

# Problem 0

```{r load_libraries}
library(tidyverse) #loads tidyverse package
library(purrr) #loads tidyverse package
set.seed(1)
```

```{r setup}
knitr::opts_chunk$set(echo = TRUE) #shows all code chunks
knitr::opts_chunk$set(
  fig.width = 12,
  fig.asp = .6,
  out.width = "100%") #sets figure dimensions

theme_set(theme_minimal() + theme(legend.position = "bottom")) #sets default figure theme
```

# Problem 1



# Problem 2

First, we load the CSV file of homicide data from Washington Past, clean the variable names, and change unknown values to NA for consistency (since some but not all variables already have missing/unknown values already coded as NA). 

```{r load_homicides}
homicides = 
  read_csv("data/homicide_data.csv") %>% #loads csv file
  janitor::clean_names() %>% #cleans variable names
  gdata::unknownToNA("Unknown", warning = FALSE) #changes all "unknown" values to "NA"
```

In the resulting dataset, there are ``r nrow(homicides)`` rows (observations) and ``r ncol(homicides)`` columns (variables). The variables' names are ``r names(homicides)``. We can see `uid` provides the victim's ID (with a prefix for the city proceeding a number), `reported_date` gives the date on which the homicide was reported (YYYYMMDD), `victim_last` gives the victim's last name, `victim_first` gives the victim's first name, `victim_race` gives the victim's race (Asian, Black, Hispanic, Other, White), `victim_age` gives the victim's age in years, `victim_sex` gives the victim's sex (male, female), `city`, `state`, `lat` (latitude), and `long` (longitude) give the location of the homicide,  and `disposition` gives the outcome of the case (closed by arrest, closed without arrest, open/no arrest).

Next, we create a city_state variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”). The table showing this data is outputted below the associated code.

```{r citystate}
homicides = 
  homicides %>% 
  mutate(state = replace(state, state == "AL", "OK")) %>% 
  mutate(state = replace(state, state == "wI", "WI")) %>% 
  mutate(city_state = paste(city, state, sep = ", ")) %>% #creates city_state variable
  group_by(city_state) %>% #groups by city_state
  summarize(n_unsolved = sum(disposition == 'Closed without arrest' | disposition == 'Open/No arrest'), n_total = n()) #creates new variables for total homicides and total unsolved homicides

homicides_table = 
  homicides %>% 
  knitr::kable(digits = 4) #creates table

homicides_table #outputs table
```

For the city of Baltimore, MD, we use the `prop.test` function to estimate the proportion of homicides that are unsolved; save the output of `prop.test` as an R object, apply the `broom::tidy` to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r baltimore}
baltimore_md = 
  homicides %>% 
  filter(city_state == "Baltimore, MD")

x = baltimore_md %>% pull(n_unsolved)
n = baltimore_md %>% pull(n_total)

baltimore_test = 
  prop.test(x, n, p = NULL, 
          alternative = c("two.sided", "less", "greater"), 
          conf.level = 0.95, correct = TRUE) %>% 
  broom::tidy() %>% 
  janitor::clean_names()

baltimore_table = 
  baltimore_test %>% 
  select(estimate, starts_with("conf")) %>% 
  knitr::kable(digits = 4) #creates table

baltimore_table
```

Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

```{r all_cities}
all_cities = 
  homicides %>%
  mutate(test = map2(n_unsolved, n_total, ~ prop.test(.x, .y, conf.level=0.95) %>% 
  broom::tidy())) %>% 
  unnest(test) %>% 
  janitor::clean_names() %>% 
  select(city_state, estimate, conf_low, conf_high) %>% 
  mutate(city_state = as.factor(city_state))

all_cities_table = 
  all_cities %>%
  knitr::kable(digits = 4) #creates table

all_cities_table
```

Finally, we create a plot that shows the estimates and CIs for each city, adding error bars based on the upper and lower limits. We organize cities according to the proportion of unsolved homicides.

```{r cities_plot}
all_cities = 
  all_cities %>%
  mutate(city_state = reorder(city_state, -estimate))

ggplot(all_cities, aes( x = city_state, y = estimate)) + 
  geom_bar(stat = 'identity', alpha = 0.7, fill = "#d98fcc") + 
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high), alpha = 0.7) + 
  theme(plot.title = element_text(size = 20, face = "bold")) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 14)) + 
  theme(axis.text.y = element_text(size = 14)) + 
  theme(axis.title = element_text(size = 14, face = "bold")) + 
  theme(plot.caption = element_text(size = 12)) + 
  labs(
      title = "Proportion of Unsolved Homicides in U.S. Cities with 95% Confidence Intervals",
      x = "City, State",
      y = "Proportion of Unsolved Homicides",
      caption = "Data from Washington Post.")
```


# Problem 3

In this problem, we will conduct a simulation to explore power in a one-sample t-test. First, we set the following design elements:

* Fix n=30
* Fix σ=5
* Set μ=0. Generate 5000 datasets from the model x∼Normal[μ,σ]

For each dataset, we save mu hat and the p-value arising from a test of H: mu = 0 and alpha = 0.05. To obtain the estimate and p-value, we use `broom::tidy` to clean the output of `t.test`.

```{r simulation}
sim_t_test = function(sample_size=30, mu, sigma = 5){

sample = rnorm(n = sample_size, mean = 0, sd = sigma)

test_results = t.test(sample)

test_results %>% 
  broom::tidy()
}

sim_results_df = 
  expand_grid(
    sample_size = c(30),
    iter = 1:100
  ) %>% 
  mutate(
    estimate_df = map(sample_size, sim_t_test)
  ) %>% 
  unnest(estimate_df)
```


```{r iteration}
sim_t_test = function(mean, n = 30, sd = 5){

sample = rnorm(mean, n = 30, sd = 5)

test_results = t.test(sample)

test_results %>% 
  broom::tidy()
}

sim_results_df = 
  expand_grid(
    true_mean = c(1, 2, 3, 4, 5, 6),
    iter = 1:100
  ) %>% 
  mutate(
    estimate_df = map(true_mean, sim_t_test)
  ) %>% 
  unnest(estimate_df)
```